{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What-If Tool on COMPAS\n",
    "Copyright 2019 Google LLC. SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "This notebook shows use of the [What-If Tool](https://pair-code.github.io/what-if-tool) on the COMPAS dataset.\n",
    "\n",
    "For ML fairness background on COMPAS see:\n",
    "- https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\n",
    "- https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm\n",
    "- http://www.crj.org/assets/2017/07/9_Machine_bias_rejoinder.pdf\n",
    "\n",
    "The dataset is from the [COMPAS kaggle page](https://www.kaggle.com/danofer/compass).\n",
    "\n",
    "This notebook trains a linear classifier on the on the COMPAS dataset to mimic the behavior of the the COMPAS recidivism classifier. We can then analyze our COMPAS proxy model for fairness using the What-If Tool.\n",
    "\n",
    "The specific binary classification task for this model is to determine if a person belongs in the \"Low\" risk class according to COMPAS (negative class), or the \"Medium\" or \"High\" risk class (positive class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a tf feature spec from the dataframe and columns specified.\n",
    "def create_feature_spec(df, columns=None):\n",
    "    feature_spec = {}\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for f in columns:\n",
    "        if df[f].dtype is np.dtype(np.int64):\n",
    "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.int64)\n",
    "        elif df[f].dtype is np.dtype(np.float64):\n",
    "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.float32)\n",
    "        else:\n",
    "            feature_spec[f] = tf.io.FixedLenFeature(shape=(), dtype=tf.string)\n",
    "    return feature_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates simple numeric and categorical feature columns from a feature spec and a\n",
    "# list of columns from that spec to use.\n",
    "#\n",
    "# NOTE: Models might perform better with some feature engineering such as bucketed\n",
    "# numeric columns and hash-bucket/embedding columns for categorical features.\n",
    "def create_feature_columns(columns, feature_spec):\n",
    "    ret = []\n",
    "    for col in columns:\n",
    "        if feature_spec[col].dtype is tf.int64 or feature_spec[col].dtype is tf.float32:\n",
    "            ret.append(tf.feature_column.numeric_column(col))\n",
    "        else:\n",
    "            ret.append(tf.feature_column.indicator_column(\n",
    "                tf.feature_column.categorical_column_with_vocabulary_list(col, list(df[col].unique()))))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An input function for providing input to a model from tf.Examples\n",
    "def tfexamples_input_fn(examples, feature_spec, label, mode=tf.estimator.ModeKeys.EVAL,\n",
    "                       num_epochs=None, \n",
    "                       batch_size=64):\n",
    "    def ex_generator():\n",
    "        for i in range(len(examples)):\n",
    "            yield examples[i].SerializeToString()\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "      ex_generator, tf.dtypes.string, tf.TensorShape([]))\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        dataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(lambda tf_example: parse_tf_example(tf_example, label, feature_spec))\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parses Tf.Example protos into features for the input function.\n",
    "def parse_tf_example(example_proto, label, feature_spec):\n",
    "    parsed_features = tf.io.parse_example(serialized=example_proto, features=feature_spec)\n",
    "    target = parsed_features.pop(label)\n",
    "    return parsed_features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a dataframe into a list of tf.Example protos.\n",
    "def df_to_examples(df, columns=None):\n",
    "    examples = []\n",
    "    if columns == None:\n",
    "        columns = df.columns.values.tolist()\n",
    "    for index, row in df.iterrows():\n",
    "        example = tf.train.Example()\n",
    "        for col in columns:\n",
    "            if df[col].dtype is np.dtype(np.int64):\n",
    "                example.features.feature[col].int64_list.value.append(int(row[col]))\n",
    "            elif df[col].dtype is np.dtype(np.float64):\n",
    "                example.features.feature[col].float_list.value.append(row[col])\n",
    "            elif row[col] == row[col]:\n",
    "                example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n",
    "        examples.append(example)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a dataframe column into a column of 0's and 1's based on the provided test.\n",
    "# Used to force label columns to be numeric for binary classification using a TF estimator.\n",
    "def make_label_column_numeric(df, label_column, test):\n",
    "    df[label_column] = np.where(test(df[label_column]), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training dataset from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://storage.googleapis.com/what-if-tool-resources/computefest2019/cox-violent-parsed_filt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18316, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>...</th>\n",
       "      <th>vr_charge_desc</th>\n",
       "      <th>type_of_assessment</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>score_text</th>\n",
       "      <th>screening_date</th>\n",
       "      <th>v_type_of_assessment</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>Male</td>\n",
       "      <td>18/04/1947</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>14/08/2013</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>Male</td>\n",
       "      <td>18/04/1947</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk of Recidivism</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>14/08/2013</td>\n",
       "      <td>Risk of Violence</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id              name   first       last   sex         dob  age  \\\n",
       "0  1.0  miguel hernandez  miguel  hernandez  Male  18/04/1947   69   \n",
       "1  2.0  miguel hernandez  miguel  hernandez  Male  18/04/1947   69   \n",
       "\n",
       "           age_cat   race  juv_fel_count  ...  vr_charge_desc  \\\n",
       "0  Greater than 45  Other              0  ...             NaN   \n",
       "1  Greater than 45  Other              0  ...             NaN   \n",
       "\n",
       "   type_of_assessment  decile_score.1  score_text  screening_date  \\\n",
       "0  Risk of Recidivism               1         Low      14/08/2013   \n",
       "1  Risk of Recidivism               1         Low      14/08/2013   \n",
       "\n",
       "  v_type_of_assessment v_decile_score  v_score_text priors_count.1 event  \n",
       "0     Risk of Violence              1           Low              0     0  \n",
       "1     Risk of Violence              1           Low              0     0  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify input columns and columns to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out entries with no indication of recidivism or no compass score\n",
    "df = df[df['is_recid'] != -1]\n",
    "df = df[df['decile_score'] != -1]\n",
    "\n",
    "# Rename recidivism column\n",
    "df['recidivism_within_2_years'] = df['is_recid']\n",
    "\n",
    "# Make the COMPASS label column numeric (0 and 1), for use in our model\n",
    "df['COMPASS_determination'] = np.where(df['score_text'] == 'Low', 0, 1)\n",
    "\n",
    "# Set column to predict\n",
    "label_column = 'COMPASS_determination'\n",
    "\n",
    "# Get list of all columns from the dataset we will use for model input or output.\n",
    "input_features = ['sex', 'age', 'race', 'priors_count', 'juv_fel_count', 'juv_misd_count', 'juv_other_count']\n",
    "features_and_labels = input_features + [label_column]\n",
    "\n",
    "features_for_file = input_features + ['recidivism_within_2_years', 'COMPASS_determination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert dataset to tf.Example protos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = df_to_examples(df, features_for_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 2000 #@param {type: \"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature spec for the classifier\n",
    "feature_spec = create_feature_spec(df, features_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/k7/pvgyxzd171bdd36dggbbxmrr0000gn/T/tmpe3jbl6dw\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/k7/pvgyxzd171bdd36dggbbxmrr0000gn/T/tmpe3jbl6dw', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /Users/cinny/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From <ipython-input-4-39371231781b>:8: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From <ipython-input-4-39371231781b>:8: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cinny/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1700: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cinny/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/ftrl.py:148: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/k7/pvgyxzd171bdd36dggbbxmrr0000gn/T/tmpe3jbl6dw/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6931472, step = 0\n",
      "INFO:tensorflow:global_step/sec: 132.1\n",
      "INFO:tensorflow:loss = 0.55241585, step = 100 (0.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.308\n",
      "INFO:tensorflow:loss = 0.4251055, step = 200 (0.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.548\n",
      "INFO:tensorflow:loss = 0.5206141, step = 300 (0.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.895\n",
      "INFO:tensorflow:loss = 0.5033277, step = 400 (0.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.304\n",
      "INFO:tensorflow:loss = 0.47528714, step = 500 (0.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.491\n",
      "INFO:tensorflow:loss = 0.38060758, step = 600 (0.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.564\n",
      "INFO:tensorflow:loss = 0.56559455, step = 700 (0.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.089\n",
      "INFO:tensorflow:loss = 0.470867, step = 800 (0.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.514\n",
      "INFO:tensorflow:loss = 0.50074905, step = 900 (0.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.061\n",
      "INFO:tensorflow:loss = 0.59917986, step = 1000 (0.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.364\n",
      "INFO:tensorflow:loss = 0.40826884, step = 1100 (0.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.636\n",
      "INFO:tensorflow:loss = 0.4932337, step = 1200 (0.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.788\n",
      "INFO:tensorflow:loss = 0.4391241, step = 1300 (0.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.362\n",
      "INFO:tensorflow:loss = 0.5906882, step = 1400 (0.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.018\n",
      "INFO:tensorflow:loss = 0.5307807, step = 1500 (0.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.442\n",
      "INFO:tensorflow:loss = 0.6755155, step = 1600 (0.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.021\n",
      "INFO:tensorflow:loss = 0.43987823, step = 1700 (0.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.21\n",
      "INFO:tensorflow:loss = 0.53403085, step = 1800 (0.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.885\n",
      "INFO:tensorflow:loss = 0.48047778, step = 1900 (0.777 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /var/folders/k7/pvgyxzd171bdd36dggbbxmrr0000gn/T/tmpe3jbl6dw/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
      "INFO:tensorflow:Loss for final step: 0.5476798.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x7fea8888cee0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and train the classifier\n",
    "train_inpf = functools.partial(tfexamples_input_fn, examples, feature_spec, label_column)\n",
    "classifier = tf.estimator.LinearClassifier(\n",
    "    feature_columns=create_feature_columns(input_features, feature_spec))\n",
    "classifier.train(train_inpf, steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "-- Cinny's prelim eval of the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, truth_label='recidivism_within_2_years', pred_label='COMPASS_determination'):\n",
    "    tp = df[(df[truth_label]==1) & (df[pred_label]==1)]\n",
    "    tn = df[(df[truth_label]==0) & (df[pred_label]==0)]\n",
    "    fp = df[(df[truth_label]==0) & (df[pred_label]==1)]\n",
    "    fn = df[(df[truth_label]==1) & (df[pred_label]==0)]\n",
    "    return tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(tp, tn, fp, fn):\n",
    "    return len(tp), len(tn), len(fp), len(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(df, truth_label='recidivism_within_2_years', pred_label='COMPASS_determination'):\n",
    "    tp, tn, fp, fn = get_data(df)\n",
    "    TP, TN, FP, FN = get_length(tp, tn, fp, fn)\n",
    "    return (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(df, truth_label='recidivism_within_2_years', pred_label='COMPASS_determination'):\n",
    "    tp, tn, fp, fn = get_data(df)\n",
    "    TP, TN, FP, FN = get_length(tp, tn, fp, fn)\n",
    "    return (TP)/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(df, truth_label='recidivism_within_2_years', pred_label='COMPASS_determination'):\n",
    "    tp, tn, fp, fn = get_data(df)\n",
    "    TP, TN, FP, FN = get_length(tp, tn, fp, fn)\n",
    "    return (TP)/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(df, truth_label='recidivism_within_2_years', pred_label='COMPASS_determination'):\n",
    "    P = get_precision(df)\n",
    "    R = get_recall(df)\n",
    "    return 2*(P*R)/(P+R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "`Accuracy = (TP+TN)/(TP+FP+FN+TN)`\n",
    "\n",
    "Accuracy is a valid choice of evaluation for classification problems which are well balanced and not skewed or No class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6261799874134676"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "`Precision = (TP)/(TP+FP)`\n",
    "\n",
    "Precision is a valid choice of evaluation metric when we want to be very sure of our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6002136752136752"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_precision(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "\n",
    "`Recall = (TP)/(TP+FN)`\n",
    "\n",
    "Recall is a valid choice of evaluation metric when we want to capture as many positives as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6680142687277051"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recall(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score\n",
    "\n",
    "`F1 = 2 * (precision * recall) / (precision + recall)`\n",
    "\n",
    "The F1 score is a number between 0 (worst) and 1 (best). It is used when you want your model to have both good precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F_beta\n",
    "\n",
    "`F_beta = (1 + beta^2) * (precision * recall) / ( (beta^2 * precision) + recall )`\n",
    "\n",
    "The F1 score gives equal weight to precision and recall. `beta` means we give `beta` times more importance to recall as precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6323016319639843"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_f1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race              recidivism_within_2_years  COMPASS_determination\n",
       "African-American  0                          0                        1212\n",
       "                                             1                        1421\n",
       "                  1                          0                         746\n",
       "                                             1                        2264\n",
       "Asian             0                          0                          23\n",
       "                                             1                           6\n",
       "                  1                          0                           2\n",
       "                                             1                           8\n",
       "Caucasian         0                          0                        1410\n",
       "                                             1                         629\n",
       "                  1                          0                         653\n",
       "                                             1                         823\n",
       "Hispanic          0                          0                         366\n",
       "                                             1                         143\n",
       "                  1                          0                         132\n",
       "                                             1                         141\n",
       "Native American   0                          0                          15\n",
       "                                             1                           3\n",
       "                  1                          0                           2\n",
       "                                             1                          15\n",
       "Other             0                          0                         250\n",
       "                                             1                          65\n",
       "                  1                          0                         125\n",
       "                                             1                          75\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['race', 'recidivism_within_2_years', 'COMPASS_determination']).count()['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, tn, fp, fn = get_data(df)\n",
    "TP, TN, FP, FN = get_length(tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6261799874134676"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(TP+TN)/(TP+FP+FN+TN)\n",
    "get_accuracy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6159844054580896"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2264+1212)/(2264+1421+746+1212) #African American"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6352773826458037"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(823+1410)/(823+629+653+1410) #Caucasian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
